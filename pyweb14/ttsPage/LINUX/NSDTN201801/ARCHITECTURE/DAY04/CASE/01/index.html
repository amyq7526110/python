<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <title>CASE</title>
    <meta http-equiv="content-type" content="text/html; charset=utf-8" />
    <script type="text/javascript" src="index.files/jquery.min.js">
    </script>
    <script type="text/javascript" src="index.files/jquery.snippet.js">
    </script>
    <script type="text/javascript" src="index.files/main.js">
    </script>
    <link type="text/css" href="index.files/index.css" rel="Stylesheet" />
    <link type="text/css" href="index.files/jquery.snippet.css" rel="Stylesheet" />
  </head>
  <body>
    <div class="source_style_case">
      <a name="page_top_case" id="top_anchor" />
      <a id="link_top" href="#page_top_case">Top</a>
      <h1>NSD ARCHITECTURE DAY04</h1>
      <ol class="index">
        <li>
          <a href="#case1">案例1：导入数据</a>
        </li>
        <li>
          <a href="#case2">案例2：综合练习</a>
        </li>
      </ol>
      <a name="case1">
      </a>
      <h2>1 案例1：导入数据</h2>
      <h3>1.1 问题</h3>
      <p>本案例要求批量导入数据：</p>
      <ul class="list">
        <li>批量导入数据并查看</li>
      </ul>
      <h3>1.2 步骤</h3>
      <p>实现此案例需要按照如下步骤进行。</p>
      <p class="number">步骤一：导入数据</p>
      <p>使用POST方式批量导入数据，数据格式为json，url 编码使用data-binary导入含有index配置的json文件</p>
      <pre class="code">[root@room9pc01 ~]# scp /var/ftp/elk/*.gz 192.168.1.66:/root/[root@kibana ~]# gzip  -d logs.jsonl.gz [root@kibana ~]#  gzip  -d accounts.json.gz [root@kibana ~]# gzip  -d shakespeare.json.gz[root@kibana ~]# curl -X POST "http://192.168.1.61:9200/_bulk" \ --data-binary @shakespeare.json[root@kibana ~]# curl -X POST "http://192.168.1.61:9200/xixi/haha/_bulk" \ --data-binary @accounts.json  //索引是xixi，类型是haha，必须导入索引和类型，没有索引，要加上[root@kibana ~]# curl -X POST "http://192.168.1.61:9200/_bulk"  \ --data-binary @logs.jsonl</pre>
      <p>2）使用GET查询结果</p>
      <pre class="code">[root@kibana ~]# curl -XGET 'http://192.168.1.61:9200/_mget?pretty' -d '{ "docs":[     {        "_index":"shakespeare",        "_type:":"act",        "_id":0},{        "_index":"shakespeare",        "_type:":"line",        "_id":0},{        "_index":"xixi",        "_type:":"haha",        "_id":25}]}'{		//查询的结果  "docs" : [ {    "_index" : "shakespeare",    "_type" : "act",    "_id" : "0",    "_version" : 1,    "found" : true,    "_source" : {      "line_id" : 1,      "play_name" : "Henry IV",      "speech_number" : "",      "line_number" : "",      "speaker" : "",      "text_entry" : "ACT I"    }  }, {    "_index" : "shakespeare",    "_type" : "act",    "_id" : "0",    "_version" : 1,    "found" : true,    "_source" : {      "line_id" : 1,      "play_name" : "Henry IV",      "speech_number" : "",      "line_number" : "",      "speaker" : "",      "text_entry" : "ACT I"    }  }, {    "_index" : "xixi",    "_type" : "haha",    "_id" : "25",    "_version" : 1,    "found" : true,    "_source" : {      "account_number" : 25,      "balance" : 40540,      "firstname" : "Virginia",      "lastname" : "Ayala",      "age" : 39,      "gender" : "F",      "address" : "171 Putnam Avenue",      "employer" : "Filodyne",      "email" : "virginiaayala@filodyne.com",      "city" : "Nicholson",      "state" : "PA"    }  } ]}</pre>
      <p class="number">步骤二：使用kibana查看数据是否导入成功</p>
      <p>1）数据导入以后查看logs是否导入成功，如图-1所示：</p>
      <pre class="code">[root@se5 ~]# firefox http://192.168.1.65:9200/_plugin/head/</pre>
      <div class="image">
        <img src="index.files/image001.png" />
        <p>图-1</p>
      </div>
      <p>2）kibana导入数据，如图-2所示：</p>
      <pre class="code">[root@kibana ~]# firefox  http://192.168.1.66:5601</pre>
      <div class="image">
        <img src="index.files/image002.png" />
        <p>图-2</p>
      </div>
      <p>3）成功创建会有logstash-*，如图-3所示：</p>
      <p>/<p>图-3</p></p>
      <p>4）导入成功之后选择Discover，如图-4所示：</p>
      <div class="image">
        <img src="index.files/image003.png" />
        <p>图-4</p>
      </div>
      <p>注意： 这里没有数据的原因是导入日志的时间段不对，默认配置是最近15分钟，在这可以修改一下时间来显示</p>
      <p>5）kibana修改时间，选择Lsat 15 miuntes，如图-5所示：</p>
      <div class="image">
        <img src="index.files/image004.png" />
        <p>图-5</p>
      </div>
      <p>6）选择Absolute，如图-6所示：</p>
      <div class="image">
        <img src="index.files/image005.png" />
        <p>图-6</p>
      </div>
      <p>7）选择时间2015-5-15到2015-5-22，如图-7所示：</p>
      <div class="image">
        <img src="index.files/image006.png" />
        <p>图-7</p>
      </div>
      <p>8）查看结果，如图-8所示：</p>
      <div class="image">
        <img src="index.files/image007.png" />
        <p>图-8</p>
      </div>
      <p>9）除了柱状图，Kibana还支持很多种展示方式 ，如图-9所示：</p>
      <div class="image">
        <img src="index.files/image008.png" />
        <p>图-9</p>
      </div>
      <p>10）做一个饼图，选择Pie chart，如图-10所示：</p>
      <div class="image">
        <img src="index.files/image009.png" />
        <p>图-10</p>
      </div>
      <p>11）选择from a new serach，如图-11所示：</p>
      <div class="image">
        <img src="index.files/image010.png" />
        <p>图-11</p>
      </div>
      <p>12）选择Spilt Slices，如图-12所示：</p>
      <div class="image">
        <img src="index.files/image011.png" />
        <p>图-12</p>
      </div>
      <p>13）选择Trems,Memary(也可以选择其他的，这个不固定)，如图-13所示：</p>
      <div class="image">
        <img src="index.files/image012.png" />
        <p>图-13</p>
      </div>
      <p>14）结果，如图-14所示：</p>
      <div class="image">
        <img src="index.files/image013.png" />
        <p>图-14</p>
      </div>
      <p>15）保存后可以在Dashboard查看，如图-15所示：</p>
      <div class="image">
        <img src="index.files/image014.png" />
        <p>图-15</p>
      </div>
      <a name="case2">
      </a>
      <h2>2 案例2：综合练习</h2>
      <h3>2.1 问题</h3>
      <p>本案例要求：</p>
      <ul class="list">
        <li>练习插件 </li>
        <li>安装一台Apache服务并配置 </li>
        <li>使用filebeat收集Apache服务器的日志 </li>
        <li>使用grok处理filebeat发送过来的日志 </li>
        <li>存入elasticsearch </li>
      </ul>
      <h3>2.2 步骤</h3>
      <p>实现此案例需要按照如下步骤进行。</p>
      <p class="number">步骤一：安装logstash</p>
      <p>1）配置主机名，ip和yum源，配置/etc/hosts（请把se1-se5和kibana主机配置和logstash一样的/etc/hosts）</p>
      <pre class="code">[root@logstash ~]# vim /etc/hosts192.168.1.61 se1192.168.1.62 se2192.168.1.63 se3192.168.1.64 se4192.168.1.65 se5192.168.1.66 kibana192.168.1.67 logstash</pre>
      <p>2）安装java-1.8.0-openjdk和logstash</p>
      <pre class="code">[root@logstash ~]#  yum -y install java-1.8.0-openjdk[root@logstash ~]# yum -y install logstash[root@logstash ~]#  java -versionopenjdk version "1.8.0_131"OpenJDK Runtime Environment (build 1.8.0_131-b12)OpenJDK 64-Bit Server VM (build 25.131-b12, mixed mode)[root@logstash ~]# touch /etc/logstash/logstash.conf[root@logstash ~]#  /opt/logstash/bin/logstash  --versionlogstash 2.3.4[root@logstash ~]# /opt/logstash/bin/logstash-plugin  list   //查看插件...logstash-input-stdin	//标准输入插件logstash-output-stdout	//标准输出插件...[root@logstash ~]# vim /etc/logstash/logstash.confinput{    stdin{   }}filter{}output{    stdout{   }}[root@logstash ~]# /opt/logstash/bin/logstash -f /etc/logstash/logstash.conf //启动并测试Settings: Default pipeline workers: 2Pipeline main startedaa		//logstash 配置从标准输入读取输入源,然后从标准输出输出到屏幕2018-09-15T06:19:28.724Z logstash aa</pre>
      <p>备注：若不会写配置文件可以找帮助，插件文档的位置：</p>
      <p>https://github.com/logstash-plugins</p>
      <p>3）codec类插件</p>
      <pre class="code">[root@logstash ~]# vim /etc/logstash/logstash.confinput{    stdin{    codec =&gt; "json"		//输入设置为编码json   }}filter{}output{    stdout{    codec =&gt; "rubydebug"		//输出设置为rubydebug   }}[root@logstash ~]# /opt/logstash/bin/logstash -f /etc/logstash/logstash.conf Settings: Default pipeline workers: 2Pipeline main started{"a":1}{             "a" =&gt; 1,      "@version" =&gt; "1",    "@timestamp" =&gt; "2018-09-15T06:34:14.538Z",          "host" =&gt; "logstash"}</pre>
      <p>4）file模块插件</p>
      <pre class="code">[root@logstash ~]# vim /etc/logstash/logstash.confinput{  file {    path          =&gt; [ "/tmp/a.log", "/var/tmp/b.log" ]   sincedb_path   =&gt; "/var/lib/logstash/sincedb"	//记录读取文件的位置   start_position =&gt; "beginning"				//配置第一次读取文件从什么地方开始   type           =&gt; "testlog"					//类型名称  }}filter{}output{    stdout{    codec =&gt; "rubydebug"}}[root@logstash ~]# touch /tmp/a.log[root@logstash ~]# touch /var/tmp/b.log[root@logstash ~]#  /opt/logstash/bin/logstash -f  /etc/logstash/logstash.conf </pre>
      <p>另开一个终端：写入数据</p>
      <pre class="code">[root@logstash ~]#  echo a1 &gt; /tmp/a.log [root@logstash ~]#  echo b1 &gt; /var/tmp/b.log</pre>
      <p>之前终端查看：</p>
      <pre class="code"> [root@logstash ~]#  /opt/logstash/bin/logstash -f  /etc/logstash/logstash.confSettings: Default pipeline workers: 2Pipeline main started{       "message" =&gt; "a1",      "@version" =&gt; "1",    "@timestamp" =&gt; "2018-09-15T06:44:30.671Z",          "path" =&gt; "/tmp/a.log",          "host" =&gt; "logstash",          "type" =&gt; "testlog"}{       "message" =&gt; "b1",      "@version" =&gt; "1",    "@timestamp" =&gt; "2018-09-15T06:45:04.725Z",          "path" =&gt; "/var/tmp/b.log",          "host" =&gt; "logstash",          "type" =&gt; "testlog"}	</pre>
      <p>5）tcp、udp模块插件</p>
      <pre class="code">[root@logstash ~]#  vim /etc/logstash/logstash.confinput{  file {    path          =&gt; [ "/tmp/a.log", "/var/tmp/b.log" ]   sincedb_path   =&gt; "/var/lib/logstash/sincedb"   start_position =&gt; "beginning"   type           =&gt; "testlog"  }  tcp {     host =&gt; "0.0.0.0"     port =&gt; "8888"     type =&gt; "tcplog"}   udp {     host =&gt; "0.0.0.0"     port =&gt; "9999"     type =&gt; "udplog"}}filter{}output{    stdout{    codec =&gt; "rubydebug"}} [root@logstash ~]#  /opt/logstash/bin/logstash -f  /etc/logstash/logstash.conf //启动</pre>
      <p>另开一个终端查看，可以看到端口</p>
      <pre class="code">[root@logstash tmp]#  netstat -antup | grep 8888tcp6       0      0 :::8888                 :::*                    LISTEN      22191/java          [root@logstash tmp]# netstat -antup | grep 9999udp6       0      0 :::9999                 :::*                                22191/java</pre>
      <p>在另一台主机上写一个脚本，发送数据，使启动的logstash可以接收到数据</p>
      <pre class="code">[root@se5 ~]# vim tcp.shfunction sendmsg(){  if [[ "$1" == "tcp" ]];then         exec 9&lt;&gt;/dev/tcp/192.168.1.67/8888   else         exec 9&lt;&gt;/dev/udp/192.168.1.67/9999   fi      echo "$2" &gt;&amp;9      exec 9&lt;&amp;-}[root@se5 ~]# . tcp.sh		//重新载入一下[root@se5 ~]# sendmsg udp "is tcp test" [root@se5 ~]# sendmsg udp "is tcp ss"</pre>
      <p>logstash主机查看结果</p>
      <pre class="code">[root@logstash ~]#  /opt/logstash/bin/logstash -f  /etc/logstash/logstash.confSettings: Default pipeline workers: 2Pipeline main started{       "message" =&gt; "is tcp test\n",      "@version" =&gt; "1",    "@timestamp" =&gt; "2018-09-15T07:45:00.638Z",          "type" =&gt; "udplog",          "host" =&gt; "192.168.1.65"}{       "message" =&gt; "is tcp ss\n",      "@version" =&gt; "1",    "@timestamp" =&gt; "2018-09-15T07:45:08.897Z",          "type" =&gt; "udplog",          "host" =&gt; "192.168.1.65"}</pre>
      <p>6）syslog插件练习</p>
      <pre class="code">[root@logstash ~]#  systemctl  list-unit-files | grep syslogrsyslog.service                               enabled syslog.socket                                 static  [root@logstash ~]#  vim /etc/logstash/logstash.conf   start_position =&gt; "beginning"   type           =&gt; "testlog"  }  tcp {     host =&gt; "0.0.0.0"     port =&gt; "8888"     type =&gt; "tcplog"}   udp {     host =&gt; "0.0.0.0"     port =&gt; "9999"     type =&gt; "udplog"}  syslog {     port =&gt; "514"     type =&gt; "syslog"  }}filter{}output{    stdout{    codec =&gt; "rubydebug"}}</pre>
      <p>另一个终端查看是否检测到514</p>
      <pre class="code">[root@logstash ~]#  netstat -antup | grep 514tcp6       0      0 :::514                  :::*                    LISTEN      22728/java          udp6       0      0 :::514                  :::*                                22728/java</pre>
      <p>另一台主机上面操作,本地写的日志本地可以查看</p>
      <pre class="code">[root@se5 ~]# vim /etc/rsyslog.conflocal0.info                                   /var/log/mylog  //自己添加这一行[root@se5 ~]# systemctl restart rsyslog	//重启rsyslog[root@se5 ~]#  ll /var/log/mylog		//提示没有那个文件或目录ls: cannot access /var/log/mylog: No such file or directory[root@se5 ~]# logger -p local0.info -t nsd "elk"		//写日志[root@se5 ~]#  ll /var/log/mylog		//再次查看，有文件-rw------- 1 root root 29 Sep 15 16:23 /var/log/mylog  [root@se5 ~]# tail  /var/log/mylog   //可以查看到写的日志Sep 15 16:23:25 se5 nsd: elk[root@se5 ~]# tail  /var/log/messages  //可以查看到写的日志，因为配置文件里有写以.info结尾的可以收到...Sep 15 16:23:25 se5 nsd: elk</pre>
      <p>把本地的日志发送给远程1.67</p>
      <pre class="code">[root@se5 ~]# vim /etc/rsyslog.conflocal0.info                     @192.168.1.67:514 //写一个@或两个@@都可以，一个@代表udp，两个@@代表tcp[root@se5 ~]# systemctl restart rsyslog[root@se5 ~]# logger  -p local0.info -t nds "001 elk"[root@logstash bin]# /opt/logstash/bin/logstash -f  /etc/logstash/logstash.conf  //检测到写的日志{           "message" =&gt; "001 elk",          "@version" =&gt; "1",        "@timestamp" =&gt; "2018-09-05T09:15:47.000Z",              "type" =&gt; "syslog",              "host" =&gt; "192.168.1.65",          "priority" =&gt; 134,         "timestamp" =&gt; "Jun  5 17:15:47",         "logsource" =&gt; "kibana",           "program" =&gt; "nds1801",          "severity" =&gt; 6,          "facility" =&gt; 16,    "facility_label" =&gt; "local0",    "severity_label" =&gt; "Informational"}</pre>
      <p>rsyslog.conf配置向远程发送数据，远程登陆1.65的时侯，把登陆日志的信息（/var/log/secure）转发给logstash即1.67这台机器</p>
      <pre class="code">[root@se5 ~]#  vim /etc/rsyslog.conf57 authpriv.*                                             @@192.168.1.67:514  //57行的/var/log/secure改为@@192.168.1.67:514 [root@se5 ~]# systemctl restart rsyslog[root@logstash ~]# /opt/logstash/bin/logstash -f  /etc/logstash/logstash.conf  //找一台主机登录1.65，logstash主机会有数据Settings: Default pipeline workers: 2Pipeline main started{           "message" =&gt; "Accepted password for root from 192.168.1.254 port 33780 ssh2\n",          "@version" =&gt; "1",        "@timestamp" =&gt; "2018-09-15T08:40:57.000Z",              "type" =&gt; "syslog",              "host" =&gt; "192.168.1.65",          "priority" =&gt; 86,         "timestamp" =&gt; "Sep 15 16:40:57",         "logsource" =&gt; "se5",           "program" =&gt; "sshd",               "pid" =&gt; "26133",          "severity" =&gt; 6,          "facility" =&gt; 10,    "facility_label" =&gt; "security/authorization",    "severity_label" =&gt; "Informational"}{           "message" =&gt; "pam_unix(sshd:session): session opened for user root by (uid=0)\n",          "@version" =&gt; "1",        "@timestamp" =&gt; "2018-09-15T08:40:57.000Z",              "type" =&gt; "syslog",              "host" =&gt; "192.168.1.65",          "priority" =&gt; 86,         "timestamp" =&gt; "Sep 15 16:40:57",         "logsource" =&gt; "se5",           "program" =&gt; "sshd",               "pid" =&gt; "26133",          "severity" =&gt; 6,          "facility" =&gt; 10,    "facility_label" =&gt; "security/authorization",    "severity_label" =&gt; "Informational"</pre>
      <p>7）filter grok插件</p>
      <p>grok插件：</p>
      <p>解析各种非结构化的日志数据插件</p>
      <p>grok使用正则表达式把飞结构化的数据结构化</p>
      <p>在分组匹配，正则表达式需要根据具体数据结构编写</p>
      <p>虽然编写困难，但适用性极广</p>
      <pre class="code">[root@logstash ~]#  vim /etc/logstash/logstash.confinput{        stdin{ codec =&gt; "json" }  file {    path          =&gt; [ "/tmp/a.log", "/var/tmp/b.log" ]   sincedb_path   =&gt; "/var/lib/logstash/sincedb"   start_position =&gt; "beginning"   type           =&gt; "testlog"  }  tcp {     host =&gt; "0.0.0.0"     port =&gt; "8888"     type =&gt; "tcplog"}   udp {     host =&gt; "0.0.0.0"     port =&gt; "9999"     type =&gt; "udplog"}  syslog {     port =&gt; "514"     type =&gt; "syslog"  }}filter{   grok{        match =&gt; ["message", "(?&lt;key&gt;reg)"]  }}output{    stdout{    codec =&gt; "rubydebug"}}[root@se5 ~]# yum -y install httpd[root@se5 ~]# systemctl restart httpd[root@se5 ~]# vim /var/log/httpd/access_log192.168.1.254 - - [15/Sep/2018:18:25:46 +0800] "GET / HTTP/1.1" 403 4897 "-" "Mozilla/5.0 (Windows NT 6.1; WOW64; rv:52.0) Gecko/20100101 Firefox/52.0"</pre>
      <p>复制/var/log/httpd/access_log的日志到logstash下的/tmp/a.log</p>
      <pre class="code">[root@logstash ~]# vim /tmp/a.log192.168.1.254 - - [15/Sep/2018:18:25:46 +0800] "GET / HTTP/1.1" 403 4897 "-" "Mozilla/5.0 (Windows NT 6.1; WOW64; rv:52.0) Gecko/20100101 Firefox/52.0"[root@logstash ~]#  /opt/logstash/bin/logstash -f  /etc/logstash/logstash.conf//出现message的日志，但是没有解析是什么意思Settings: Default pipeline workers: 2Pipeline main started{       "message" =&gt; ".168.1.254 - - [15/Sep/2018:18:25:46 +0800] \"GET / HTTP/1.1\" 403 4897 \"-\" \"Mozilla/5.0 (Windows NT 6.1; WOW64; rv:52.0) Gecko/20100101 Firefox/52.0\"",      "@version" =&gt; "1",    "@timestamp" =&gt; "2018-09-15T10:26:51.335Z",          "path" =&gt; "/tmp/a.log",          "host" =&gt; "logstash",          "type" =&gt; "testlog",          "tags" =&gt; [        [0] "_grokparsefailure"    ]}</pre>
      <p>若要解决没有解析的问题，同样的方法把日志复制到/tmp/a.log，logstash.conf配置文件里面修改grok</p>
      <p>查找正则宏路径</p>
      <pre class="code">[root@logstash ~]# cd  /opt/logstash/vendor/bundle/ \ jruby/1.9/gems/logstash-patterns-core-2.0.5/patterns/[root@logstash ~]# vim grok-patterns  //查找COMBINEDAPACHELOGCOMBINEDAPACHELOG %{COMMONAPACHELOG} %{QS:referrer} %{QS:agent}[root@logstash ~]#  vim /etc/logstash/logstash.conf...filter{   grok{        match =&gt; ["message", "%{COMBINEDAPACHELOG}"]  }}...</pre>
      <p>解析出的结果</p>
      <pre class="code"> [root@logstash ~]#  /opt/logstash/bin/logstash -f  /etc/logstash/logstash.conf  Settings: Default pipeline workers: 2Pipeline main started{        "message" =&gt; "192.168.1.254 - - [15/Sep/2018:18:25:46 +0800] \"GET /noindex/css/open-sans.css HTTP/1.1\" 200 5081 \"http://192.168.1.65/\" \"Mozilla/5.0 (Windows NT 6.1; WOW64; rv:52.0) Gecko/20100101 Firefox/52.0\"",       "@version" =&gt; "1",     "@timestamp" =&gt; "2018-09-15T10:55:57.743Z",           "path" =&gt; "/tmp/a.log",           "host" =&gt; "logstash",           "type" =&gt; "testlog",       "clientip" =&gt; "192.168.1.254",          "ident" =&gt; "-",           "auth" =&gt; "-",      "timestamp" =&gt; "15/Sep/2018:18:25:46 +0800",           "verb" =&gt; "GET",        "request" =&gt; "/noindex/css/open-sans.css",    "httpversion" =&gt; "1.1",       "response" =&gt; "200",          "bytes" =&gt; "5081",       "referrer" =&gt; "\"http://192.168.1.65/\"",          "agent" =&gt; "\"Mozilla/5.0 (Windows NT 6.1; WOW64; rv:52.0) Gecko/20100101 Firefox/52.0\""}</pre>
      <p class="number">步骤二：安装Apache服务，用filebeat收集Apache服务器的日志，存入elasticsearch</p>
      <p>1）在之前安装了Apache的主机上面安装filebeat</p>
      <pre class="code">[root@se5 ~]#  yum -y install filebeat[root@se5 ~]#  vim/etc/filebeat/filebeat.yml  paths:	- /var/log/httpd/access_log   //日志的路径，短横线加空格代表yml格式document_type: apachelog    //文档类型elasticsearch:		//加上注释hosts: ["localhost:9200"]				//加上注释logstash:					//去掉注释hosts: ["192.168.1.67:5044"] 	//去掉注释,logstash那台主机的ip[root@se5 ~]# systemctl start filebeat[root@logstash ~]#  vim /etc/logstash/logstash.confinput{        stdin{ codec =&gt; "json" }        beats{            port =&gt; 5044}  file {    path          =&gt; [ "/tmp/a.log", "/var/tmp/b.log" ]   sincedb_path   =&gt; "/dev/null"   start_position =&gt; "beginning"   type           =&gt; "testlog"  }  tcp {     host =&gt; "0.0.0.0"     port =&gt; "8888"     type =&gt; "tcplog"}   udp {     host =&gt; "0.0.0.0"     port =&gt; "9999"     type =&gt; "udplog"}  syslog {     port =&gt; "514"     type =&gt; "syslog"  }}filter{if [type] == "apachelog"{   grok{        match =&gt; ["message", "%{COMBINEDAPACHELOG}"]  }}}output{      stdout{ codec =&gt; "rubydebug" }      if [type] == "filelog"{      elasticsearch {          hosts =&gt; ["192.168.1.61:9200", "192.168.1.62:9200"]          index =&gt; "filelog"          flush_size =&gt; 2000          idle_flush_time =&gt; 10      }}} [root@logstash logstash]#  /opt/logstash/bin/logstash  \ -f  /etc/logstash/logstash.conf</pre>
      <p>打开另一终端查看5044是否成功启动</p>
      <pre class="code">[root@logstash ~]#  netstat -antup | grep 5044tcp6       0      0 :::5044                 :::*                    LISTEN      23776/java[root@se5 ~]#  firefox 192.168.1.65   //ip为安装filebeat的那台机器</pre>
      <p>回到原来的终端，有数据</p>
      <p>2）修改logstash.conf文件</p>
      <pre class="code">[root@logstash logstash]# vim logstash.conf...output{      stdout{ codec =&gt; "rubydebug" }      if [type] == "apachelog"{      elasticsearch {          hosts =&gt; ["192.168.1.61:9200", "192.168.1.62:9200"]          index =&gt; "apachelog"          flush_size =&gt; 2000          idle_flush_time =&gt; 10      }}}</pre>
      <p>浏览器访问Elasticsearch，有apachelog，如图-16所示：</p>
      <div class="image">
        <img src="index.files/image015.png" />
        <p>图-16</p>
      </div>
    </div>
  </body>
</html>